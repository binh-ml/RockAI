{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "boxed-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "satisfactory-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    import h5py\n",
    "    import numpy as np\n",
    "    h5f = h5py.File(filepath, 'r')\n",
    "    X = h5f['X'][:]\n",
    "    classnames = [s.decode('utf-8') for s in h5f['classname'][:]]\n",
    "    filenames = [s.decode('utf-8') for s in h5f['filename'][:]]\n",
    "    h5f.close()\n",
    "    return X, np.array(classnames), np.array(filenames)\n",
    "\n",
    "def create_train_test_idx(classnames):\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(data=enumerate(classnames), columns=['index', 'classname'])\n",
    "    test_df = None\n",
    "    train_df = None\n",
    "    for classname in df['classname'].unique():\n",
    "        test_tmp_df = df[df['classname']==classname].sample(50, replace=False, random_state=1234)\n",
    "        train_tmp_df = df[(df['classname']==classname) & ~(df['index'].isin(test_tmp_df['index']))]\n",
    "        test_df = test_tmp_df if test_df is None else pd.concat([test_df, test_tmp_df])\n",
    "        train_df = train_tmp_df if train_df is None else pd.concat([train_df, train_tmp_df])    \n",
    "    return train_df['index'].values, test_df['index'].values\n",
    "    \n",
    "X, classnames, filenames = load_data('data/RockAI_images_224x224.h5')\n",
    "train_idx, test_idx = create_train_test_idx(classnames)\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train = [classnames[i] for i in train_idx]\n",
    "y_test = [classnames[i] for i in test_idx]\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "#Pre-process the data\n",
    "X_train = tf.keras.applications.resnet50.preprocess_input(X_train)\n",
    "X_test = tf.keras.applications.resnet50.preprocess_input(X_test)\n",
    "y_train = [0 if x=='No_RA' else 1 for x in y_train]\n",
    "y_test = [0 if x=='No_RA' else 1 for x in y_test]\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intensive-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range = 30,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "# datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "starting-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([256]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.25]))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam']))\n",
    "\n",
    "METRIC = 'accuracy'\n",
    "num_epochs = 50\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "        metrics=[hp.Metric(METRIC, display_name=METRIC)],\n",
    "    )\n",
    "\n",
    "\n",
    "def train_test_model(hparams):\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "    import time\n",
    "    import numpy as np\n",
    "    \n",
    "    base_model = tf.keras.applications.resnet50.ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model = tf.keras.models.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=hparams[HP_OPTIMIZER],        \n",
    "        metrics=[METRIC],\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train, epochs=num_epochs, verbose=1,\n",
    "              callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)])\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_time = time.time() - start_time\n",
    "    \n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    C = confusion_matrix(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "        \n",
    "    return C, acc, f1, train_time, test_time\n",
    "\n",
    "\n",
    "def run(run_dir, hparams, log_result_filepath):\n",
    "    import datetime\n",
    "    \n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        C, acc, f1, train_time, test_time = train_test_model(hparams)\n",
    "        tf.summary.scalar('Accuracy', acc, step=1)\n",
    "        tf.summary.scalar('F1-score', f1, step=1)\n",
    "        \n",
    "    with open(log_result_filepath, 'a') as fp:\n",
    "        fp.write(f\"timestamp: {datetime.datetime.now()}, \")\n",
    "        fp.write(f\"model: ResNet50, \")\n",
    "        for h in hparams:\n",
    "            fp.write(f\"{h.name}: {hparams[h]}, \")\n",
    "        fp.write(f\"data_augmentation: standard \\n\")\n",
    "        fp.write(f\"\\tConfusion matrix: {C.tolist()}\")\n",
    "        fp.write(f\"\\tAccuracy: {acc:0.4}, F1-score: {f1:0.4}, Train time: {train_time:0.4}, Test_time: {test_time:0.4}\\n\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "boxed-computer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 256, 'dropout': 0.25, 'optimizer': 'adam'}\n",
      "Epoch 1/50\n",
      "43/43 [==============================] - 12s 161ms/step - loss: 0.8893 - accuracy: 0.6099\n",
      "Epoch 2/50\n",
      "43/43 [==============================] - 6s 143ms/step - loss: 0.3199 - accuracy: 0.9259\n",
      "Epoch 3/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.2149 - accuracy: 0.9381\n",
      "Epoch 4/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.1954 - accuracy: 0.9474\n",
      "Epoch 5/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.1741 - accuracy: 0.9480\n",
      "Epoch 6/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.1414 - accuracy: 0.9443\n",
      "Epoch 7/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.1455 - accuracy: 0.9449\n",
      "Epoch 8/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.1202 - accuracy: 0.9522\n",
      "Epoch 9/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.1574 - accuracy: 0.9478\n",
      "Epoch 10/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.1357 - accuracy: 0.9536\n",
      "Epoch 11/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.1229 - accuracy: 0.9625\n",
      "Epoch 12/50\n",
      "43/43 [==============================] - 6s 145ms/step - loss: 0.0904 - accuracy: 0.9677\n",
      "Epoch 13/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.0930 - accuracy: 0.9694\n",
      "Epoch 14/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.0894 - accuracy: 0.9707\n",
      "Epoch 15/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.0995 - accuracy: 0.9687\n",
      "Epoch 16/50\n",
      "43/43 [==============================] - 6s 145ms/step - loss: 0.0833 - accuracy: 0.9755\n",
      "Epoch 17/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.0982 - accuracy: 0.9691\n",
      "Epoch 18/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.1070 - accuracy: 0.9672\n",
      "Epoch 19/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.0883 - accuracy: 0.9656\n",
      "Epoch 20/50\n",
      "43/43 [==============================] - 6s 145ms/step - loss: 0.0841 - accuracy: 0.9674\n",
      "Epoch 21/50\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.0859 - accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in (HP_DROPOUT.domain.values):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_OPTIMIZER: optimizer,\n",
    "            }\n",
    "            for _ in range(1):\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                run('logs/hparam_tuning/' + run_name, hparams, 'logs/hparam_tuning_score.txt')\n",
    "                session_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RockAI",
   "language": "python",
   "name": "rockai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
