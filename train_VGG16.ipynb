{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "varying-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "native-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elect-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    h5f = h5py.File(filepath, 'r')\n",
    "    X_train = h5f['X_train'][:]\n",
    "    y_train = h5f['y_train'][:]\n",
    "    X_test = h5f['X_test'][:]\n",
    "    y_test = h5f['y_test'][:]\n",
    "    h5f.close()\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data('data/RockAI_test_50_images.h5')\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "#Pre-process the data\n",
    "X_train = preprocess_input(X_train)\n",
    "X_test = preprocess_input(X_test)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "historical-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser\n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=True))\n",
    "# datagen = ImageDataGenerator()\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baking-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224, 224)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(VGG16(weights='imagenet'))\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aquatic-windsor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 8s 193ms/step - loss: 0.6305 - accuracy: 0.6503\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 8s 194ms/step - loss: 0.2845 - accuracy: 0.9416\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 8s 194ms/step - loss: 0.2116 - accuracy: 0.9470\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 0.1899 - accuracy: 0.9549\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 0.2368 - accuracy: 0.9397\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 0.2216 - accuracy: 0.9443\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 0.1928 - accuracy: 0.9545\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 0.2159 - accuracy: 0.9452\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 8s 198ms/step - loss: 0.2117 - accuracy: 0.9463\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 8s 196ms/step - loss: 0.2261 - accuracy: 0.9410\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "historytemp = model.fit(datagen.flow(X_train, y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                        epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "reflected-cameroon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 51ms/step - loss: 1.5165 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5165082216262817, 0.5]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='sgd', metrics=[tf.keras.metrics.AUC()])\n",
    "\n",
    "historytemp = model.fit(datagen.flow(X_train, y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                        epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-designation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RockAI",
   "language": "python",
   "name": "rockai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
