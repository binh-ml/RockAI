{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "surprising-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "democratic-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    import h5py\n",
    "    import numpy as np\n",
    "    h5f = h5py.File(filepath, 'r')\n",
    "    X = h5f['X'][:]\n",
    "    classnames = [s.decode('utf-8') for s in h5f['classname'][:]]\n",
    "    filenames = [s.decode('utf-8') for s in h5f['filename'][:]]\n",
    "    h5f.close()\n",
    "    return X, np.array(classnames), np.array(filenames)\n",
    "\n",
    "def create_train_test_idx(classnames):\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(data=enumerate(classnames), columns=['index', 'classname'])\n",
    "    test_df = None\n",
    "    train_df = None\n",
    "    for classname in df['classname'].unique():\n",
    "        test_tmp_df = df[df['classname']==classname].sample(50, replace=False, random_state=1234)\n",
    "        train_tmp_df = df[(df['classname']==classname) & ~(df['index'].isin(test_tmp_df['index']))]\n",
    "        test_df = test_tmp_df if test_df is None else pd.concat([test_df, test_tmp_df])\n",
    "        train_df = train_tmp_df if train_df is None else pd.concat([train_df, train_tmp_df])    \n",
    "    return train_df['index'].values, test_df['index'].values\n",
    "    \n",
    "X, classnames, filenames = load_data('data/RockAI_images_224x224.h5')\n",
    "train_idx, test_idx = create_train_test_idx(classnames)\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train = [classnames[i] for i in train_idx]\n",
    "y_test = [classnames[i] for i in test_idx]\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "#Pre-process the data\n",
    "X_train = preprocess_input(X_train)\n",
    "X_test = preprocess_input(X_test)\n",
    "y_train = [0 if x=='No_RA' else 1 for x in y_train]\n",
    "y_test = [0 if x=='No_RA' else 1 for x in y_test]\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dirty-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        import numpy as np\n",
    "        \n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "#     get_random_eraser(v_l=0, v_h=1, pixel_level=True),\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range = 30,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "# datagen = ImageDataGenerator(preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=True))\n",
    "# datagen = ImageDataGenerator()\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "preceding-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze four convolution blocks\n",
    "for layer in vgg_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Make sure you have frozen the correct layers\n",
    "# for i, layer in enumerate(vgg_model.layers):\n",
    "#     print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "super-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the vgg convolutional base model\n",
    "model.add(vgg_model)\n",
    "\n",
    "# Add new layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# tf.keras.utils.plot_model(model, show_shapes=True, to_file='outdir/vgg_model.png')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vocal-chess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "42/42 [==============================] - 13s 197ms/step - loss: 26.6235 - accuracy: 0.8624\n",
      "Epoch 2/30\n",
      "42/42 [==============================] - 7s 160ms/step - loss: 1.6273 - accuracy: 0.9244\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 7s 165ms/step - loss: 0.2243 - accuracy: 0.9510\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 7s 162ms/step - loss: 0.2510 - accuracy: 0.9524\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 7s 162ms/step - loss: 0.1493 - accuracy: 0.9569\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 7s 163ms/step - loss: 0.1103 - accuracy: 0.9681\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 7s 164ms/step - loss: 0.1469 - accuracy: 0.9625\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 7s 163ms/step - loss: 0.1305 - accuracy: 0.9787\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 7s 163ms/step - loss: 0.0883 - accuracy: 0.9742\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 7s 163ms/step - loss: 0.1001 - accuracy: 0.9643\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 7s 165ms/step - loss: 0.0698 - accuracy: 0.9706\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 7s 162ms/step - loss: 0.0886 - accuracy: 0.9663\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 7s 160ms/step - loss: 0.1308 - accuracy: 0.9709\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 7s 162ms/step - loss: 0.0789 - accuracy: 0.9775\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 7s 162ms/step - loss: 0.0752 - accuracy: 0.9751\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.0781 - accuracy: 0.9754\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.1244 - accuracy: 0.9630\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.0646 - accuracy: 0.9801\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.0819 - accuracy: 0.9719\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 7s 162ms/step - loss: 0.0783 - accuracy: 0.9703\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 7s 162ms/step - loss: 0.0954 - accuracy: 0.9727\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 7s 163ms/step - loss: 0.0501 - accuracy: 0.9820\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.0629 - accuracy: 0.9799\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.0723 - accuracy: 0.9811\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 7s 163ms/step - loss: 0.0969 - accuracy: 0.9741\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 7s 162ms/step - loss: 0.0666 - accuracy: 0.9809\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 7s 164ms/step - loss: 0.0520 - accuracy: 0.9842\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 7s 164ms/step - loss: 0.0727 - accuracy: 0.9786\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 7s 162ms/step - loss: 0.0791 - accuracy: 0.9776\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.0502 - accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "historytemp = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                        epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sixth-third",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 271ms/step - loss: 0.4366 - accuracy: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.436609148979187, 0.8700000047683716]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RockAI",
   "language": "python",
   "name": "rockai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
