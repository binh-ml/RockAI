{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model_name': 'vgg16',\n",
    "    'num_units': 256,\n",
    "    'dropout': 0.25,\n",
    "    'optimizer': 'adam',\n",
    "    'input_shape': (224, 224, 3),\n",
    "    'retrain': False,\n",
    "    'data_filepath': 'data/RockAI_images_224x224.h5',\n",
    "    'test_size': 100,\n",
    "    'num_epochs': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    def load_h5(filepath):\n",
    "        import h5py\n",
    "        import numpy as np\n",
    "        h5f = h5py.File(filepath, 'r')\n",
    "        X = h5f['X'][:]\n",
    "        classnames = [s.decode('utf-8') for s in h5f['classname'][:]]\n",
    "        filenames = [s.decode('utf-8') for s in h5f['filename'][:]]\n",
    "        h5f.close()\n",
    "        return X, np.array(classnames), np.array(filenames)\n",
    "\n",
    "    def create_train_test_idx(classnames):\n",
    "        import pandas as pd\n",
    "        df = pd.DataFrame(data=enumerate(classnames), columns=['index', 'classname'])\n",
    "        test_df = None\n",
    "        train_df = None\n",
    "        for classname in df['classname'].unique():\n",
    "            test_tmp_df = df[df['classname']==classname].sample(config['test_size'], replace=False, random_state=1234)\n",
    "            train_tmp_df = df[(df['classname']==classname) & ~(df['index'].isin(test_tmp_df['index']))]\n",
    "            test_df = test_tmp_df if test_df is None else pd.concat([test_df, test_tmp_df])\n",
    "            train_df = train_tmp_df if train_df is None else pd.concat([train_df, train_tmp_df])    \n",
    "        return train_df['index'].values, test_df['index'].values\n",
    "  \n",
    "    # Load data\n",
    "    X, classnames, filenames = load_data(config['data_filepath'])\n",
    "    train_idx, test_idx = create_train_test_idx(classnames)\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train = [classnames[i] for i in train_idx]\n",
    "    y_test = [classnames[i] for i in test_idx]\n",
    "\n",
    "    num_classes = len(classnames)\n",
    "\n",
    "    # Pre-process the data\n",
    "    if config['model_name'] == 'vgg16':\n",
    "        X_train = tf.keras.applications.vgg16.preprocess_input(X_train)\n",
    "        X_test = tf.keras.applications.vgg16.preprocess_input(X_test)\n",
    "    elif config['model_name'] == 'resnet50':\n",
    "        X_train = tf.keras.applications.resnet50.preprocess_input(X_train)\n",
    "        X_test = tf.keras.applications.resnet50.preprocess_input(X_test)\n",
    "    elif config['model_name'] == 'inceptionv3':\n",
    "        X_train = tf.keras.applications.inception_v3.preprocess_input(X_train)\n",
    "        X_test = tf.keras.applications.inception_v3.preprocess_input(X_test)\n",
    "    else:\n",
    "        raise Exception.ValueError('Model name is not supported')\n",
    "        \n",
    "    y_train = [0 if x=='No_RA' else 1 for x in y_train]\n",
    "    y_test = [0 if x=='No_RA' else 1 for x in y_test]\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "# Data augmentation\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range = 30,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    if config['model_name'] == 'vgg16':\n",
    "        base_model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape=config['input_shape'])  \n",
    "        for layer in base_model.layers[:]:\n",
    "            layer.trainable = retrain\n",
    "\n",
    "        model = tf.keras.models.Sequential([\n",
    "            base_model,\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(config['num_unit'], activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dropout(config['dropout']),\n",
    "            tf.keras.layers.Dense(2, activation=tf.nn.softmax),\n",
    "        ])\n",
    "        \n",
    "    elif config['model_name'] == 'resnet50':\n",
    "        base_model = tf.keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=config['input_shape'])\n",
    "        for layer in base_model.layers[:]:\n",
    "            layer.trainable = retrain\n",
    "\n",
    "        model = tf.keras.models.Sequential([\n",
    "            base_model,\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(config['num_unit'], activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dropout(config['dropout']),\n",
    "            tf.keras.layers.Dense(2, activation=tf.nn.softmax),\n",
    "        ])\n",
    "        \n",
    "    elif config['model_name'] == 'inceptionv3':\n",
    "        base_model = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False, input_shape=config['input_shape'])\n",
    "        for layer in base_model.layers[:]:\n",
    "            layer.trainable = retrain\n",
    "\n",
    "        model = tf.keras.models.Sequential([\n",
    "            base_model,\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(config['num_unit'], activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dropout(config['dropout']),\n",
    "            tf.keras.layers.Dense(2, activation=tf.nn.softmax),\n",
    "        ])\n",
    "    \n",
    "    else:\n",
    "        raise Exception.ValueError('Model name is not supported')\n",
    "        \n",
    "    model.compile(\n",
    "        loss=config['categorical_crossentropy'],\n",
    "        optimizer=config['optimizer'],        \n",
    "        metrics=config['metric'],\n",
    "    )\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(config):\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "    import time\n",
    "    import numpy as np\n",
    "    \n",
    "    base_model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model = tf.keras.models.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        tf.keras.layers.Dense(2, activation=tf.nn.softmax),\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=hparams[HP_OPTIMIZER],        \n",
    "        metrics=[METRIC],\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train, epochs=num_epochs, verbose=1)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_time = time.time() - start_time\n",
    "    \n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    C = confusion_matrix(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "        \n",
    "    return C, acc, f1, train_time, test_time\n",
    "\n",
    "\n",
    "def run(run_dir, hparams, log_result_filepath):\n",
    "    import datetime\n",
    "    \n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        C, acc, f1, train_time, test_time = train_test_model(hparams)\n",
    "        tf.summary.scalar('Accuracy', acc, step=1)\n",
    "        tf.summary.scalar('F1-score', f1, step=1)\n",
    "        \n",
    "    with open(log_result_filepath, 'a') as fp:\n",
    "        fp.write(f\"timestamp: {datetime.datetime.now()}, \")\n",
    "        fp.write(f\"model: VGG16, \")\n",
    "        for h in hparams:\n",
    "            fp.write(f\"{h.name}: {hparams[h]}, \")\n",
    "        fp.write(f\"data_augmentation: standard \\n\")\n",
    "        fp.write(f\"\\tConfusion matrix: {C.tolist()}\")\n",
    "        fp.write(f\"\\tAccuracy: {acc:0.4}, F1-score: {f1:0.4}, Train time: {train_time:0.4}, Test_time: {test_time:0.4}\\n\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 256, 'dropout': 0.25, 'optimizer': 'adam'}\n",
      "Epoch 1/50\n",
      "43/43 [==============================] - 16s 242ms/step - loss: 100.4333 - accuracy: 0.8482\n",
      "Epoch 2/50\n",
      "43/43 [==============================] - 8s 185ms/step - loss: 0.2277 - accuracy: 0.9483\n",
      "Epoch 3/50\n",
      "43/43 [==============================] - 8s 185ms/step - loss: 0.1881 - accuracy: 0.9586\n",
      "Epoch 4/50\n",
      "43/43 [==============================] - 8s 186ms/step - loss: 0.2155 - accuracy: 0.9508\n",
      "Epoch 5/50\n",
      "43/43 [==============================] - 8s 186ms/step - loss: 0.1922 - accuracy: 0.9555\n",
      "Epoch 6/50\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 0.1990 - accuracy: 0.9506\n",
      "Epoch 7/50\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 0.1776 - accuracy: 0.9525\n",
      "Epoch 8/50\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 0.2067 - accuracy: 0.9434\n",
      "Epoch 9/50\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 0.1831 - accuracy: 0.9483\n",
      "Epoch 10/50\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 0.2014 - accuracy: 0.9466\n",
      "Epoch 11/50\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 0.1960 - accuracy: 0.9470\n",
      "Epoch 12/50\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 0.2447 - accuracy: 0.9395\n",
      "Epoch 13/50\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 0.1847 - accuracy: 0.9493\n",
      "Epoch 14/50\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 0.1870 - accuracy: 0.9513\n",
      "Epoch 15/50\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 0.2218 - accuracy: 0.9428\n",
      "Epoch 16/50\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 0.1993 - accuracy: 0.9476\n",
      "Epoch 17/50\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 0.1810 - accuracy: 0.9498\n",
      "Epoch 18/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1847 - accuracy: 0.9492\n",
      "Epoch 19/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1898 - accuracy: 0.9414\n",
      "Epoch 20/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1513 - accuracy: 0.9497\n",
      "Epoch 21/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1633 - accuracy: 0.9477\n",
      "Epoch 22/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1393 - accuracy: 0.9519\n",
      "Epoch 23/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1592 - accuracy: 0.9503\n",
      "Epoch 24/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1748 - accuracy: 0.9515\n",
      "Epoch 25/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1383 - accuracy: 0.9479\n",
      "Epoch 26/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1449 - accuracy: 0.9513\n",
      "Epoch 27/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1172 - accuracy: 0.9602\n",
      "Epoch 28/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1683 - accuracy: 0.9420\n",
      "Epoch 29/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1435 - accuracy: 0.9515\n",
      "Epoch 30/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1413 - accuracy: 0.9616\n",
      "Epoch 31/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1033 - accuracy: 0.9634\n",
      "Epoch 32/50\n",
      "43/43 [==============================] - 8s 188ms/step - loss: 0.1605 - accuracy: 0.9522\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in (HP_DROPOUT.domain.values):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_OPTIMIZER: optimizer,\n",
    "            }\n",
    "            for _ in range(1):\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                run('logs/hparam_tuning/' + run_name, hparams, 'logs/hparam_tuning_score.txt')\n",
    "                session_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rockai",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
